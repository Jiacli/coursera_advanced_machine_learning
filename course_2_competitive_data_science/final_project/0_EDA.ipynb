{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will do most of the exploratory data analysis (we will do some later after we have created certain features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Predict total sales for every product and store in the next month.\n",
    "\n",
    "Success is measured by low error in terms of root mean squared difference\n",
    "\n",
    "$$\\displaystyle \\operatorname {RMSD} ={\\sqrt {\\frac {\\sum _{t=1}^{T}({\\hat {y}}_{t}-y_{t})^{2}}{T}}}$$\n",
    "\n",
    "**NOTE**: The `RMSE` must be clipped to `[0,20]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File descriptions\n",
    "\n",
    "* `sales_train.csv` - the training set. Daily historical data from January 2013 to October 2015.\n",
    "* `test.csv` - the test set. You need to forecast the sales for these shops and products for November 2015.\n",
    "* `sample_submission.csv` - a sample submission file in the correct format.\n",
    "* `items.csv - supplemental` information about the items/products.\n",
    "* `item_categories.csv` - supplemental information about the items categories.\n",
    "* `shops.csv` - supplemental information about the shops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('.').absolute().joinpath('data')\n",
    "\n",
    "sales_train = pd.read_csv(data_dir.joinpath('sales_train.csv.gz'))\n",
    "sales_test = pd.read_csv(data_dir.joinpath('test.csv.gz'))\n",
    "items = pd.read_csv(data_dir.joinpath('items.csv'))\n",
    "item_categories = pd.read_csv(data_dir.joinpath('item_categories.csv'))\n",
    "shops = pd.read_csv(data_dir.joinpath('shops.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fields\n",
    "\n",
    "* `ID` - an Id that represents a (Shop, Item) tuple within the test set\n",
    "* `shop_id` - unique identifier of a shop\n",
    "* `item_id` - unique identifier of a product\n",
    "* `item_category_id` - unique identifier of item category\n",
    "* `item_cnt_day` - number of products sold. You are predicting a monthly amount of this measure\n",
    "* `item_price` - current price of an item\n",
    "* `date` - date in format dd/mm/yyyy\n",
    "* `date_block_num` - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n",
    "* `item_name` - name of item\n",
    "* `shop_name` - name of shop\n",
    "* `item_category_name` - name of item category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'sales_train has {sales_train.shape[0]} rows')\n",
    "sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'sales_test has {sales_test.shape[0]} rows')\n",
    "sales_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'items has {items.shape[0]} rows')\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'item_categories has {item_categories.shape[0]} rows')\n",
    "item_categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shops has {shops.shape[0]} rows')\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if train and test contain the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sets(train, test, col):\n",
    "    \"\"\"\n",
    "    Checks the overlap between the column values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train : DataFrame\n",
    "        The train data\n",
    "    test : DataFrame\n",
    "        The test data\n",
    "    col : str\n",
    "        The column to check the overlap of\n",
    "    \"\"\"\n",
    "    \n",
    "    train_col = set(train.loc[:, col].unique())\n",
    "    test_col = set(test.loc[:, col].unique())\n",
    "\n",
    "    total = len(train_col.union(test_col))\n",
    "    not_in_test = len(train_col - test_col)\n",
    "    not_in_train = len(test_col - train_col)\n",
    "\n",
    "    not_in_test_frac = 100*not_in_test/total\n",
    "    not_in_train_frac = 100*not_in_train/total\n",
    "\n",
    "    print(f'{not_in_test} {col} elements are in train, but not in test ({not_in_test_frac:.1f} %)')\n",
    "    print(f'{not_in_train} {col} elements are in test, but not in train ({not_in_train_frac:.1f} %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sets(sales_train, sales_test, 'shop_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_sets(sales_train, sales_test, 'item_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine the shop ids and the item ids to check how much overlap there is between the combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_item_train = sales_train.loc[:, ['shop_id','item_id']].apply(lambda cols : f'{cols[0]}_{cols[1]}', axis=1)\n",
    "shop_item_test = sales_test.loc[:, ['shop_id','item_id']].apply(lambda cols : f'{cols[0]}_{cols[1]}', axis=1)\n",
    "\n",
    "check_sets(shop_item_train.to_frame('shop_item'), shop_item_test.to_frame('shop_item'), 'shop_item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train_shop = sales_train.loc[:, 'shop_id'].unique()\n",
    "print(unique_train_shop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_test_shop = sales_test.loc[:, 'shop_id'].unique()\n",
    "print(unique_test_shop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to see any patterns here, although there could be some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_in_train = [shop for shop in unique_train_shop if shop not in unique_test_shop]\n",
    "print(only_in_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not anything obvious here either. (Remember that the train set contains all shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shop_item_train.unique()[:100])\n",
    "print(shop_item_train.unique()[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shop_item_test.unique()[:100])\n",
    "print(shop_item_test.unique()[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really obvious that whether or not there is a pattern here.\n",
    "\n",
    "Maybe we find something if we plot them in a 3-D plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True)\n",
    "sales_train.plot('shop_id', 'item_id', style='.', ax=ax1)\n",
    "sales_test.plot('shop_id', 'item_id', style='.', ax=ax2)\n",
    "ax1.set_ylabel('item_id')\n",
    "ax2.set_ylabel('item_id')\n",
    "ax1.legend().set_visible(False)\n",
    "ax2.legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appers that a stripe in the train set has been removed. Let's check that up close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True)\n",
    "sales_train.loc[sales_train.loc[:, 'item_id'] > 20000].plot('shop_id', 'item_id', style='.', ax=ax1)\n",
    "sales_test.loc[sales_test.loc[:, 'item_id'] > 20000].plot('shop_id', 'item_id', style='.', ax=ax2)\n",
    "ax1.set_ylabel('item_id')\n",
    "ax2.set_ylabel('item_id')\n",
    "ax1.legend().set_visible(False)\n",
    "ax2.legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's peculiar. This can imply that the test data is not generated completely randomly (or maybe that the train data has been partially). We can actually see several of these stripes, alebeit with smaller bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True)\n",
    "sales_train.loc[(sales_train.loc[:, 'item_id'] < 1000) & (sales_train.loc[:, 'item_id'] > 500)].plot('shop_id', 'item_id', style='.', ax=ax1)\n",
    "sales_test.loc[(sales_test.loc[:, 'item_id'] < 1000) & (sales_test.loc[:, 'item_id'] > 500)].plot('shop_id', 'item_id', style='.', ax=ax2)\n",
    "ax1.set_ylabel('item_id')\n",
    "ax2.set_ylabel('item_id')\n",
    "ax1.legend().set_visible(False)\n",
    "ax2.legend().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can appear like the shop id numbers where choosen at random, and possibly also the band and location of the item id numbers in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.loc[:, 'item_cnt_day'].hist(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a couple of outliners here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_item_cnt = sales_train.loc[:, 'item_cnt_day'].max()\n",
    "min_item_cnt = sales_train.loc[:, 'item_cnt_day'].min()\n",
    "\n",
    "print(f'Max item count {max_item_cnt}')\n",
    "print(f'Min item count {min_item_cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right outliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train.loc[:, 'item_cnt_day'] == max_item_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_item_id = sales_train.loc[sales_train.loc[:, 'item_cnt_day'] == max_item_cnt, 'item_id'].values[0]\n",
    "items.loc[items.loc[:, 'item_id'] == ro_item_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This translates to something like \"Delivery to the point of issue (Boxberry)\", where it from Google looks like Boxberry is doing shipping to Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_item_id_cat = items.loc[items.loc[:, 'item_id'] == ro_item_id, 'item_category_id'].values[0]\n",
    "item_categories.loc[item_categories.loc[:, 'item_category_id'] == ro_item_id_cat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which translates to delivery of goods...this may actually be a correct number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left outliner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train.loc[:, 'item_cnt_day'] == min_item_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This translates to something like \"Delivery to the point of issue (Boxberry)\", where it from Google looks like Boxberry is doing shipping to Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_item_id = sales_train.loc[sales_train.loc[:, 'item_cnt_day'] == min_item_cnt, 'item_id'].values[0]\n",
    "items.loc[items.loc[:, 'item_id'] == lo_item_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This translates to stickers, and (although peculiar, it could be that somebody delivered $22$ stickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clipped distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.loc[sales_train.loc[:, 'item_cnt_day'] > 100, 'item_cnt_day'].hist(ax=ax, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.loc[sales_train.loc[:, 'item_cnt_day'] < -3, 'item_cnt_day'].hist(ax=ax, bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these outliers are few, it should be fairly safe to replace them with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the clipped distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.loc[(sales_train.loc[:, 'item_cnt_day'] >= 0) & \n",
    "                (sales_train.loc[:, 'item_cnt_day'] < 100),\n",
    "                 'item_cnt_day'].hist(ax =ax, bins=200, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_train.loc[:, 'item_cnt_day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Zero values are not present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: We are clipping the final scores to $[0, 20]$, and we can test if this is better to do before or after the prediction (for the monthly aggregated values). Nevertheless, we should treat the outliners before doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that all dates are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dd.mm.yyyy to yyyy.mm.dd\n",
    "sortable_date = sales_train.loc[:, 'date'].str[6:] + '.' +\\\n",
    "                sales_train.loc[:, 'date'].str[3:5] + '.' +\\\n",
    "                sales_train.loc[:, 'date'].str[:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = sortable_date.max()\n",
    "min_date = sortable_date.min()\n",
    "print(f'First date in dataset: {min_date}')\n",
    "print(f'Last date in dataset: {max_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train.loc[:, 'date'] == f'{max_date[8:]}.{max_date[5:7]}.{max_date[:4]}'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast dates in string to timedate objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: It is here important to specify the format, else we get nonsensical dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_date = pd.to_datetime(sales_train.loc[:, 'date'], format='%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that this is not affecting the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = sales_train_date.max()\n",
    "min_date = sales_train_date.min()\n",
    "print(f'First date in dataset: {min_date}')\n",
    "print(f'Last date in dataset: {max_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train_date == max_date].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now safely replace the dates with datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[:, 'date'] = sales_train_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(sales_train.loc[:, 'date'].unique())\n",
    "date_range = pd.date_range(start=dates.min(), end=dates.max()).unique()\n",
    "n_dates = len(dates)\n",
    "n_date_range = len(date_range)\n",
    "missing_pct = (1 - (n_dates/n_date_range))*100\n",
    "print(f'{n_date_range - n_dates} days missing ({missing_pct:.1f} %)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there are some seasonal trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.groupby('date')['item_cnt_day'].sum().plot()\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High sales in January, looks like the sales are not so high in 2015 compared to the previous years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.groupby('date_block_num')['item_cnt_day'].sum().plot(ax=ax)\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the same trends are observed in the `date_block_num`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.loc[:, 'item_price'].hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price = sales_train.loc[:, 'item_price'].max()\n",
    "min_price = sales_train.loc[:, 'item_price'].min()\n",
    "\n",
    "print(f'Max price {max_price}')\n",
    "print(f'Min price {min_price}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like missing values has been encoded as $-1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.loc[sales_train.loc[:, 'item_price'] > 35000, 'item_price'].hist(ax=ax, bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$5000$ RUB was a lot of money in the time under investigation. The last point appears to be an outliner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prices = sales_train.loc[sales_train.loc[:, 'item_price'] > 40000].sort_values('item_price', ascending=False)\n",
    "high_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_max_price = high_prices.iloc[0]['item_id']\n",
    "items.loc[items.loc[:, 'item_id'] == item_max_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This translates to \"Radmin 3 - 522 individuals\". In other words, the price may be actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train.loc[:, 'item_id'] == item_max_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was only sold once. It could be that this was a special order. One could consider to remove the point, or redo the `item_id` and change the `item_cnt_day`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item for item in items.loc[:, 'item_name'] if 'admin' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.loc[items.loc[:, 'item_name'] == 'Radmin 3  - 1 лиц.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check whether this is a commonly sold product, or if it's better to just remove the data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train.loc[:, 'item_id'] == 6065]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if these are present in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test.loc[sales_test.loc[:, 'item_id'] == item_max_price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test.loc[sales_test.loc[:, 'item_id'] == 6065]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these are present in the test set, and should be taken care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_item_max_price = high_prices.iloc[1]['item_id']\n",
    "items.loc[items.loc[:, 'item_id'] == second_item_max_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible that this translates to something like express mail service. It may that this was the actual price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item id, shop id and item category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.groupby('item_id')['item_cnt_day'].sum().plot(ax=ax, style='.')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably have one dominating prodcut, let's investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_item_id = sales_train.groupby('item_id')['item_cnt_day'].sum().idxmax()\n",
    "items.loc[items.loc[:, 'item_id'] == max_item_id, 'item_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding from Google images, it looks like this translates to plastic bags, so it could be that this number is in fact huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sales_train.groupby('shop_id')['item_cnt_day'].sum().plot(ax=ax, style='.')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seem to be sane, but we note that a few shops sells a lot more then the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "merged_train = pd.merge(sales_train, items, how='left', on=['item_id'])\n",
    "merged_train.groupby('item_category_id')['item_cnt_day'].sum().plot(ax=ax, style='.')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the shop ids, it appears that a few categories are really contributing to the most of the number of items sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "corr = sales_train.corr()\n",
    "cax = ax.matshow(corr)\n",
    "fig.colorbar(cax)\n",
    "_ = ax.set_xticklabels([0]+list(corr.columns.values))\n",
    "_ = ax.set_yticklabels([0]+list(corr.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not suprisingly: The item id is correlated with the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "corr = sales_test.corr()\n",
    "cax = ax.matshow(corr)\n",
    "fig.colorbar(cax)\n",
    "_ = ax.set_xticklabels([0]+list(corr.columns.values))\n",
    "_ = ax.set_yticklabels([0]+list(corr.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrestingly enough, we see that the `shop_id` is tightly correlated with the ID number. This is a leakage we can exploit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Check if ordering is important\n",
    "* Check if shop_id_item_id is correlated with target\n",
    "* Continue investigation of data leakage\n",
    "* EDA: NA vals, empty strings, -1, very large numbers, -999999 and less, 999, 99\n",
    "* Investigating the split"
   ]
  }
 ],
 "metadata": {
  "hw_version": "1.0.0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
